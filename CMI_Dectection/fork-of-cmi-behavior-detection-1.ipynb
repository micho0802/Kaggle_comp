{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":102335,"databundleVersionId":12518947,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        # print(os.path.join(dirname, filename))\n        pass\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-06T20:28:03.013528Z","iopub.execute_input":"2025-07-06T20:28:03.014646Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/cmi-detect-behavior-with-sensor-data/train.csv\")\nprint(train.info())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_demo = pd.read_csv(\"/kaggle/input/cmi-detect-behavior-with-sensor-data/train_demographics.csv\")\nprint(train_demo.info())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv\")\nprint(test.info())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_demo = pd.read_csv(\"/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv\")\nprint(test_demo.info())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os, json, joblib, numpy as np, pandas as pd\nfrom scipy.spatial.transform import Rotation \nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom pathlib import Path\nimport warnings \nwarnings.filterwarnings(\"ignore\")\n\n\n\ndef remove_gravity_from_acc(acc_data, rot_data):\n\n    if isinstance(acc_data, pd.DataFrame):\n        acc_values = acc_data[['acc_x', 'acc_y', 'acc_z']].values\n    else:\n        acc_values = acc_data\n\n    if isinstance(rot_data, pd.DataFrame):\n        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n    else:\n        quat_values = rot_data\n\n    num_samples = acc_values.shape[0]\n    linear_accel = np.zeros_like(acc_values)\n    \n    gravity_world = np.array([0, 0, 9.81])\n\n    for i in range(num_samples):\n        if np.all(np.isnan(quat_values[i])) or np.all(np.isclose(quat_values[i], 0)):\n            linear_accel[i, :] = acc_values[i, :] \n            continue\n\n        try:\n            rotation = Rotation.from_quat(quat_values[i])\n            gravity_sensor_frame = rotation.apply(gravity_world, inverse=True)\n            linear_accel[i, :] = acc_values[i, :] - gravity_sensor_frame\n        except ValueError:\n             linear_accel[i, :] = acc_values[i, :]\n             \n    return linear_accel","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"le = LabelEncoder()\ntrain['gesture_int'] = le.fit_transform(train['gesture']).astype(np.int32)\ngesture_classes = le.classes_\ntrain['sequence_id_encode'] = le.fit_transform(train['sequence_id']).astype(np.int32)\nsequence_id_classes = le.classes_\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"  Calculating base engineered IMU features (magnitude, angle)...\")\ntrain['acc_mag'] = np.sqrt(train['acc_x']**2 + train['acc_y']**2 + train['acc_z']**2)\ntrain['rot_angle'] = 2 * np.arccos(train['rot_w'].clip(-1, 1))\n\nprint(\"  Calculating engineered IMU derivatives (jerk, angular velocity) for original acc_mag...\")\ntrain['acc_mag_jerk'] = train.groupby('sequence_id')['acc_mag'].diff().fillna(0)\ntrain['rot_angle_vel'] = train.groupby('sequence_id')['rot_angle'].diff().fillna(0)\n\nprint(\"  Removing gravity and calculating linear acceleration features...\")\n\nlinear_accel_list = []\nfor _, group in train.groupby('sequence_id'):\n    acc_data_group = group[['acc_x', 'acc_y', 'acc_z']]\n    rot_data_group = group[['rot_x', 'rot_y', 'rot_z', 'rot_w']]\n    linear_accel_group = remove_gravity_from_acc(acc_data_group, rot_data_group)\n    linear_accel_list.append(pd.DataFrame(linear_accel_group, columns=['linear_acc_x', 'linear_acc_y', 'linear_acc_z'], index=group.index))\n\ntrain_linear_accel = pd.concat(linear_accel_list)\ntrain = pd.concat([train, train_linear_accel], axis=1)\n\ntrain['linear_acc_mag'] = np.sqrt(train['linear_acc_x']**2 + train['linear_acc_y']**2 + train['linear_acc_z']**2)\ntrain['linear_acc_mag_jerk'] = train.groupby('sequence_id')['linear_acc_mag'].diff().fillna(0)\n\nmeta_cols = { ... }\n\nimu_cols_base = ['linear_acc_x', 'linear_acc_y', 'linear_acc_z']\nimu_cols_base.extend([c for c in train.columns if c.startswith('rot_') and c not in ['rot_angle', 'rot_angle_vel']])\n\nimu_engineered_features = [\n    'acc_mag', 'rot_angle',\n    'acc_mag_jerk', 'rot_angle_vel',\n    'linear_acc_mag', 'linear_acc_mag_jerk'\n]\nimu_cols = imu_cols_base + imu_engineered_features\nimu_cols = list(dict.fromkeys(imu_cols))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"imu_cols.extend([\"gesture_int\", \"sequence_id\"])\ntrain_imu = train[imu_cols]\ntrain_imu.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_imu.groupby('sequence_id')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom torch.nn.utils.rnn import pad_sequence\nfrom sklearn.model_selection import train_test_split\n\n# Group by sequence\ngrouped = train_imu.groupby(\"sequence_id\")\n\n# Store sequences and labels\nX_list = []\ny_list = []\nseq_lens = []\n\nfor seq_id, group in grouped:\n    group = group.dropna(subset=imu_cols)  # drop rows with NaNs in IMU features\n    if group.empty:\n        continue\n\n    features = group[imu_cols].values.astype(np.float32)\n    label = group['gesture_int'].iloc[0]\n\n    X_tensor = torch.tensor(features, dtype=torch.float32)\n    X_list.append(X_tensor)\n    y_list.append(label)\n    seq_lens.append(len(X_tensor))\n\n# Compute pad length = 95th percentile\npad_len = int(np.percentile(seq_lens, 95))\nprint(f\"📏 Padding to 95th percentile sequence length: {pad_len}\")\n\n# Pad sequences (post-padding)\nX_padded = pad_sequence(X_list, batch_first=True)  # (N, max_seq_len, D)\n\n# Truncate or extend to pad_len\nif X_padded.size(1) > pad_len:\n    X_padded = X_padded[:, :pad_len, :]\nelif X_padded.size(1) < pad_len:\n    pad_amt = pad_len - X_padded.size(1)\n    zero_pad = torch.zeros((X_padded.size(0), pad_amt, X_padded.size(2)))\n    X_padded = torch.cat([X_padded, zero_pad], dim=1)\n\n# Label tensor\ny_tensor = torch.tensor(y_list, dtype=torch.long)\n\n# Train/val split\nX_train, X_val, y_train, y_val = train_test_split(\n    X_padded, y_tensor, test_size=0.2, random_state=42, stratify=y_tensor\n)\n\nprint(f\"✅ IMU-only train tensor: {X_train.shape} | val tensor: {X_val.shape}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}